会话代理“Conversational agents“ 越来越多地融入到我们的日常生活中，成为泛在计算和物联网的基本要素。它们通过提供直观和有效的交互，使人们能够用自然语言直接与设备进行交流，从而促进了我们对边缘设备的访问。得益于智能手机的普及，语音助手[ 10 ]得到了前所未有的普及，使用户可以方便地访问智能手机的功能、智能家居控制、实时信息等。



尽管语音输入带来了极大的便利性，但在实际应用中，有三个主要的限制因素阻碍了它的可用性。由于隐私和安全问题的风险，语音用户界面( Voice User Interfaces，VUIs )

1 )在公共场合并不是首选选项，人们在别人面前与智能手机交谈时可能会感到尴尬[ 44 ]；

2 )依赖于准确的语音识别，这在环境嘈杂时可能是困难的；

3 )对于有言语障碍的人来说是不可用的。



为了解决VUI中的隐私和社会接受度问题，无声语音接口( Silent Speech Interface，SSI )已经成为一种很有前途的替代方案，它利用非声学信号来实现无语音的语音识别。SSI在各种情况下，特别是在那些语音交互不合适或不可用的情况下，提供了无缝和有说服力的交互。最近关于SSI的研究提出使用肌电( Electromyography，EMG ) 、超声成像、电容传感 和 视频摄像(唇读) 等多种传感方法来跟踪语音发音器的运动并解码无声语音。



我们关注最后一种方法，也称为唇读，并通过小样本学习对其进行扩展，以在智能手机上启用可定制的无声语音命令。与其他方法相比，唇读对设备要求较低，但提供了丰富的信息，具有较高的时间和空间分辨率。如今，智能手机已经成为最受欢迎的设备，其中大多数都配备了高质量的数码相机。因此，在智能手机上实现唇读系统进一步推动了便利性并降低了无声语音输入的门槛。另一方面，作为智能手机上的主要输入方式，当只有单手输入时，触摸手势可能会很繁琐。对于这种情况，沉默语音作为一种补充已经被证明是稳定和有效的



然而，在实际应用中，构建表达性唇读系统面临三大挑战。

首先，数据收集过程应尽量减少新用户的开机负担。然而，先前的SSIs方法，不仅限于基于唇读的方法，采用了从划痕中训练的模型，需要从真实用户中收集数百个样本，这导致了过度的精神和身体用户负担。

其次，在受控的实验室环境中密集收集的这些数据会导致一个有偏的模型，该模型可以对光照、人脸朝向和姿态等因素的微小变化敏感，但很少讨论该模型对未知环境的泛化能力。

第三，模型训练过程耗时且需要高端GPU，但由于多种原因(需要网络连接,计算成本高,将人脸数据上传至云端的隐私担忧等。)并不总是用户可以访问的。增加新的命令更加困难，因为它需要收集新的数据，并从头开始重新训练模型。因此，只有有限数量的预防御命令可用，而无声语音中丰富的交互空间仍等待挖掘。（成本）



在这项研究中，我们的目标是解放唇读的昂贵，同时减轻数据收集过程中的用户负担。我们提出了一种能够实现原位静音语音命令定制的少样本唇读框架。我们通过预训练一个使用对比学习目标的唇读编码器模型，该模型以半监督的方式从公共数据集中学习有效和鲁棒的视觉语音表示。

然后，我们使用一个简单的线性分类器，它可以在几秒钟内进行训练，并使用少量的学习策略将模型转移到看不见的用户和单词。因此，用户可以通过提供至少一个样例，自由地定义任何语言中的任何短语，甚至非语言的唇形手势，作为一种无声的语音命令。我们进一步通过引入Voice2Lip，一种多模态的命令注册技术，以一次性的方式从语音输入中自动学习唇读，从而最大限度地减少了用户注册新命令的负担。为了注册一个新的命令，用户只需大声说出来，然后我们的系统将从语音信号中识别出的文本作为标签来学习嘴唇的动作。



为了使LipLearner具有可靠的免提激活，我们提出了一种视觉关键词检测方法，该方法从嘴唇运动中检测出用户指定的关键词。以往的唇读界面大多使用嘴巴张开度( MOD ) [ 57、58 ]作为唯一的线索来触发无声语音输入，容易产生误激活。例如，系统可以很容易地响应用户的无意行为，例如微笑或与他人交谈。我们的唇读模型将唇部运动编码成嵌入向量，可以通过计算余弦相似度从连续输入中识别关键词。
